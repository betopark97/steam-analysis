{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381f365d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Data Management\n",
    "from typing import Optional, Dict, List, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from bson import json_util\n",
    "import bson\n",
    "import re\n",
    "import difflib\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import missingno as msno\n",
    "import flatten_json\n",
    "\n",
    "# Ignore warnings\n",
    "from bs4 import MarkupResemblesLocatorWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Import your modules\n",
    "from src import steam_api_manager\n",
    "from src import mongo_manager\n",
    "from src import postgres_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d75ee",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "# When you need to reload after changes\n",
    "importlib.reload(steam_api_manager)\n",
    "importlib.reload(mongo_manager)\n",
    "\n",
    "# Get fresh instances of your classes\n",
    "steam_api = steam_api_manager.SteamAPIManager()\n",
    "mongo_manager = mongo_manager.MongoManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8522d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c638fb",
   "metadata": {},
   "source": [
    "## Clean Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text: str):\n",
    "    if isinstance(text, str):\n",
    "        soup = BeautifulSoup(text or \"\", \"html.parser\")\n",
    "        return soup.get_text(separator=\" \").strip()\n",
    "    return text\n",
    "\n",
    "def remove_html_tags_df(df: pl.LazyFrame, cols: list) -> pl.LazyFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col(col).map_elements(remove_html_tags, return_dtype=pl.String).alias(col)\n",
    "        for col in cols\n",
    "    ])\n",
    "    \n",
    "def normalize_strings(text: str) -> str:\n",
    "    if isinstance(text, str):\n",
    "        return unicodedata.normalize('NFKC', text).strip()\n",
    "    return text\n",
    "\n",
    "def normalize_strings_df(df: pl.LazyFrame, cols: list) -> pl.LazyFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col(col).map_elements(normalize_strings, return_dtype=pl.String).alias(col)\n",
    "        for col in cols\n",
    "    ])\n",
    "    \n",
    "def strip_list_strings_df(df: pl.LazyFrame, cols: list) -> pl.LazyFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col(col).list.eval(pl.element().str.strip_chars().alias(col))\n",
    "        for col in cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1f2d8",
   "metadata": {},
   "source": [
    "## Clean Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30149b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_plus_sign(age: str) -> str:\n",
    "    if isinstance(age, str):\n",
    "        return age.replace('+', '')\n",
    "    return age\n",
    "\n",
    "def remove_plus_sign_df(df: pl.LazyFrame, cols: list) -> pl.LazyFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col(col).map_elements(remove_plus_sign, return_dtype=pl.String).alias(col)\n",
    "        for col in cols\n",
    "    ])\n",
    "    \n",
    "def convert_age_to_int_df(df: pl.LazyFrame, cols: list) -> pl.LazyFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col(col)\n",
    "        .cast(pl.Int8, strict=False)  # coerce errors to null\n",
    "        .fill_null(0)\n",
    "        .alias(col)\n",
    "        for col in cols\n",
    "    ])\n",
    "    \n",
    "def filter_age(age: int) -> int:\n",
    "    if isinstance(age, int):\n",
    "        return 0 if age < 0 or age > 21 else age\n",
    "    return age\n",
    "    \n",
    "def filter_age_df(df: pl.LazyFrame, cols: list) -> pl.LazyFrame:\n",
    "    return df.with_columns([\n",
    "        pl.col(col).map_elements(filter_age, return_dtype=pl.Int8).alias(col)\n",
    "        for col in cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722ade1",
   "metadata": {},
   "source": [
    "## Clean Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_diff_texts(a: str, b: str) -> bool:\n",
    "    a_lines = (a or \"\").splitlines()\n",
    "    b_lines = (b or \"\").splitlines()\n",
    "    diff = difflib.ndiff(a_lines, b_lines)\n",
    "    return bool(any(line.startswith(('- ', '+ ')) for line in diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65334cdc",
   "metadata": {},
   "source": [
    "# Polars Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009de745",
   "metadata": {},
   "source": [
    "this is the final layer of eda for the silver layer, the following is the order in which the data pipeline will be organized:\n",
    "\n",
    "1. Drop columns (moved to MongoDB, when reading)\n",
    "2. Filter data (moved to MongoDB, when reading)\n",
    "3. Type optimization (downcast)\n",
    "4. String & Date Normalization\n",
    "5. Missing data handling\n",
    "6. Feature Engineering / Transformations\n",
    "7. Indexing / Sorting (merging purposes)\n",
    "8. Column reordering / renaming\n",
    "9. Export / Store\n",
    "\n",
    "this time it will be done with polars to speed up the process and because polars will be used in production instead of pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854555b",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter documents\n",
    "query = {\n",
    "    # Filter type in the list\n",
    "    'type': {'$in': ['game', 'dlc', 'demo', 'series', 'episode', 'music', 'mod']},\n",
    "    # Filter only already published apps\n",
    "    'release_date.coming_soon': False\n",
    "}\n",
    "\n",
    "# Read only necessary columns\n",
    "projection = {\n",
    "    '_id': 0,\n",
    "    # Key\n",
    "    'appid': 1, 'name': 1, 'fullgame.appid': 1,\n",
    "    # Description\n",
    "    'about_the_game': 1, 'detailed_description': 1, 'short_description': 1,\n",
    "    # Images\n",
    "    'header_image': 1, 'background_raw': 1, 'screenshots': 1, 'movies': 1,\n",
    "    # Price\n",
    "    'is_free': 1, 'price_overview.currency': 1, 'price_overview.initial': 1,\n",
    "    # Meta\n",
    "    'type': 1, 'categories': 1, 'genres': 1, 'supported_languages': 1, 'controller_support': 1,\n",
    "    # Date\n",
    "    'release_date.date': 1,\n",
    "    # Contract\n",
    "    'developers': 1, 'publishers': 1, 'content_descriptors.notes': 1,\n",
    "    # Progress\n",
    "    'achievements.highlighted': 1,\n",
    "    # Computer Specs\n",
    "    'platforms': 1, \n",
    "    'pc_requirements.minimum': 1, 'pc_requirements.recommended': 1,\n",
    "    'mac_requirements.minimum': 1, 'mac_requirements.recommended': 1,\n",
    "    'linux_requirements.minimum': 1, 'linux_requirements.recommended': 1,\n",
    "    # Required Age\n",
    "    'required_age': 1,\n",
    "    'ratings.dejus.required_age': 1, 'ratings.steam_germany.required_age': 1, 'ratings.csrr.required_age': 1,\n",
    "    'ratings.esrb.required_age': 1, 'ratings.pegi.required_age': 1, 'ratings.usk.required_age': 1,\n",
    "    'ratings.oflc.required_age': 1, 'ratings.nzoflc.required_age': 1, 'ratings.kgrb.required_age': 1,\n",
    "    'ratings.mda.required_age': 1, 'ratings.fpb.required_age': 1, 'ratings.crl.required_age': 1,\n",
    "    'ratings.bbfc.required_age': 1, 'ratings.cero.required_age': 1, 'ratings.agcom.required_age': 1,\n",
    "    'ratings.cadpa.required_age': 1, 'ratings.video.required_age': 1,\n",
    "}\n",
    "\n",
    "\n",
    "# Fetch documents\n",
    "cursor = mongo_manager.database.details.find(query, projection)\n",
    "list_cursor = list(cursor)\n",
    "\n",
    "# Print count of documents\n",
    "print(f\"Number of documents: {len(list_cursor)}\")\n",
    "\n",
    "df = pd.json_normalize(list_cursor)\n",
    "df\n",
    "\n",
    "# # Convert BSON to JSON-compatible (handles ObjectId, etc.)\n",
    "# parsed_docs = json.loads(json_util.dumps(list(cursor)))\n",
    "\n",
    "# # Print count of documents\n",
    "# print(f\"Number of documents: {len(parsed_docs)}\")\n",
    "\n",
    "# df = pd.json_normalize(parsed_docs)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_type(val: Any) -> str:\n",
    "    \"\"\"Recursively detect the type inside lists or dicts.\"\"\"\n",
    "    if isinstance(val, list):\n",
    "        if not val:\n",
    "            return 'list[empty]'\n",
    "        return f\"list[{', '.join(sorted({get_deep_type(v) for v in val}))}]\"\n",
    "    elif isinstance(val, dict):\n",
    "        return \"dict\"\n",
    "    elif pd.isna(val):\n",
    "        return \"null\"\n",
    "    else:\n",
    "        return type(val).__name__\n",
    "\n",
    "def infer_column_types(df: pd.DataFrame, sample_size: int = 1000) -> dict:\n",
    "    \"\"\"Check deep types of values in a DataFrame.\"\"\"\n",
    "    type_report = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        types = Counter()\n",
    "        for val in df[col].dropna().head(sample_size):\n",
    "            try:\n",
    "                dtype = get_deep_type(val)\n",
    "                types[dtype] += 1\n",
    "            except Exception as e:\n",
    "                types[f\"Error: {str(e)}\"] += 1\n",
    "\n",
    "        type_report[col] = dict(types)\n",
    "\n",
    "    return type_report\n",
    "\n",
    "def convert_mixed_columns_to_string(df: pd.DataFrame, sample_size: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Convert columns with mixed types to string.\"\"\"\n",
    "    type_info = infer_column_types(df, sample_size)\n",
    "    mixed_columns = [col for col, types in type_info.items() if len(types) > 1]\n",
    "\n",
    "    for col in mixed_columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x) if not (x is None or isinstance(x, float) and np.isnan(x)) else None)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_pandas_to_polars = convert_mixed_columns_to_string(df, sample_size=df.shape[0])\n",
    "\n",
    "df_pl = pl.LazyFrame(\n",
    "    df_pandas_to_polars,\n",
    "    strict=False, \n",
    "    # infer_schema_length=len(parsed_docs)\n",
    "    infer_schema_length=len(list_cursor)\n",
    ")\n",
    "# drop early\n",
    "columns_to_drop = ['pc_requirements', 'mac_requirements', 'linux_requirements', 'ratings']\n",
    "columns_to_drop_in_df = [col for col in columns_to_drop if col in df_pl.columns]\n",
    "df_pl = df_pl.drop(columns_to_drop)\n",
    "\n",
    "df_pl.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948181c8",
   "metadata": {},
   "source": [
    "## Drop Columns (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dropped_columns = (\n",
    "#     df_pl.drop(\n",
    "#         [\n",
    "#             '_id.$oid', 'steam_appid', 'alternate_appid',\n",
    "#             'capsule_image', 'capsule_imagev5', 'background',\n",
    "#             'metacritic.score', 'metacritic.url',\n",
    "#             *[col for col in df.columns if 'ratings.' in col and '.required_age' not in col],\n",
    "#             'drm_notice',\n",
    "#             'price_overview.recurring_sub', 'price_overview.recurring_sub_desc',\n",
    "#             'price_overview.final', 'price_overview.discount_percent', \n",
    "#             'price_overview.initial_formatted', 'price_overview.final_formatted',\n",
    "#             'pc_requirements', 'mac_requirements', 'linux_requirements',\n",
    "#             'website', 'support_info.url', 'support_info.email', 'legal_notice', 'content_descriptors.ids',\n",
    "#             'packages', 'package_groups',\n",
    "#             'dlc', 'demos', 'fullgame.name',\n",
    "#             'reviews', 'ratings', 'recommendations.total',\n",
    "#             'ext_user_account_notice', 'achievements.total'\n",
    "#         ]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864091e",
   "metadata": {},
   "source": [
    "## Filter Data (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ddd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered = (\n",
    "#     df_dropped_columns\n",
    "#     .filter(\n",
    "#         (pl.col('type').is_in(['game', 'dlc', 'demo', 'series', 'episode', 'music', 'mod'])) &\n",
    "#         (pl.col('release_date.coming_soon') == False)\n",
    "#     )\n",
    "#     .drop('release_date.coming_soon')\n",
    "# )\n",
    "# df_filtered.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dfb979",
   "metadata": {},
   "source": [
    "## Type Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30596f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_pl.clone()\n",
    "\n",
    "cols_list = [name for name, type in df_filtered.collect_schema().items() if type == pl.List]\n",
    "\n",
    "df_type_optimized = (\n",
    "    df_filtered\n",
    "    .with_columns(\n",
    "        # Convert List[Struct{}] to List[str]\n",
    "        pl.col('categories').list.eval(pl.element().struct.field('description')),\n",
    "        pl.col('genres').list.eval(pl.element().struct.field('description')),\n",
    "        pl.col('screenshots').list.eval(pl.element().struct.field('path_full')),\n",
    "        pl.col('movies').list.eval(pl.element().struct.field('mp4').struct.field('max')),\n",
    "        # Convert String to Int\n",
    "        pl.col('fullgame.appid').cast(pl.Int64),\n",
    "        # Convert String to Boolean\n",
    "        pl\n",
    "        .when(pl.col('controller_support') == 'full')\n",
    "        .then(pl.lit(True))\n",
    "        .when(pl.col('controller_support').is_null())\n",
    "        .then(pl.lit(False))\n",
    "        .otherwise(pl.lit(None))\n",
    "        .alias('controller_support')\n",
    "    )\n",
    ")\n",
    "\n",
    "# # Check that the length of the unnested achievements.highlighted columns are the same\n",
    "# df_result = df_type_optimized.with_columns(\n",
    "#     (pl.col(\"achievements_name\").list.len() == pl.col(\"achievements_img\").list.len()).alias(\"same_length\")\n",
    "# )\n",
    "# df_result.collect().shape[0] == df_type_optimized.collect().shape[0]\n",
    "\n",
    "# Check the new types\n",
    "df_type_optimized.select([\n",
    "    'appid', 'name', \n",
    "    'categories',\n",
    "    'genres', \n",
    "    'screenshots',\n",
    "    'movies',\n",
    "    # 'achievements.highlighted'\n",
    "]).head(100).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7472e3a",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_str = [\n",
    "    col \n",
    "    for col, dtype in df_type_optimized.collect_schema().items() \n",
    "    if dtype == pl.String\n",
    "]\n",
    "cols_list_string = [\n",
    "    col \n",
    "    for col, dtype in df_type_optimized.collect_schema().items()\n",
    "    if isinstance(dtype, pl.List) and dtype.inner == pl.String\n",
    "]\n",
    "# cols_list_struct = [\n",
    "#     col \n",
    "#     for col, dtype in df_type_optimized.collect_schema().items()\n",
    "#     if isinstance(dtype, pl.List) and dtype.inner == pl.Struct\n",
    "# ]\n",
    "cols_age = [\n",
    "    col \n",
    "    for col in df_type_optimized.collect_schema().names() \n",
    "    if 'required_age' in col\n",
    "]\n",
    "\n",
    "df_cleaned = (\n",
    "    df_type_optimized\n",
    "    # Normalize all strings\n",
    "    .pipe(normalize_strings_df, cols=cols_str)\n",
    "    .pipe(remove_html_tags_df, cols=cols_str)\n",
    "    \n",
    "    # Strip all list strings\n",
    "    .pipe(strip_list_strings_df, cols=cols_list_string)\n",
    "    \n",
    "    # Clean age\n",
    "    .pipe(remove_plus_sign_df, cols=cols_age)\n",
    "    .pipe(convert_age_to_int_df, cols=cols_age)\n",
    "    .pipe(filter_age_df, cols=cols_age)\n",
    ")\n",
    "df_cleaned.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdd951",
   "metadata": {},
   "source": [
    "## Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd99f5",
   "metadata": {},
   "source": [
    "### Merged required_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_ages = (\n",
    "    df_cleaned\n",
    "    # Get the highest required age value across all required_age columns\n",
    "    .with_columns(\n",
    "        pl.max_horizontal(cols_age).alias('required_age_cleaned'),\n",
    "    )\n",
    "    # Drop all other required_age columns\n",
    "    .drop(cols_age)\n",
    "    # Rename the required_age_cleaned column\n",
    "    .rename({\n",
    "        'required_age_cleaned': 'required_age'\n",
    "    })\n",
    ")\n",
    "\n",
    "df_merged_ages.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60a70f",
   "metadata": {},
   "source": [
    "### Merged descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a081d8d",
   "metadata": {},
   "source": [
    "Add a check to see if the about_the_game or detailed_description is not an empty string\n",
    "\n",
    "this means a boolean column should be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_descriptions = (\n",
    "    df_merged_ages\n",
    "    # Compute if descriptions are different\n",
    "    .with_columns(\n",
    "        pl.struct([\"about_the_game\", \"detailed_description\"])\n",
    "        .map_elements(\n",
    "            lambda x: is_diff_texts(x[\"about_the_game\"], x[\"detailed_description\"]), \n",
    "            return_dtype=pl.Boolean\n",
    "        )\n",
    "        .alias(\"desc_has_diff\")\n",
    "    )\n",
    "\n",
    "    # Merge descriptions based on logic\n",
    "    .with_columns(\n",
    "        # Case 1: if both are empty\n",
    "        pl.when((pl.col(\"about_the_game\") == \"\") & (pl.col(\"detailed_description\") == \"\"))\n",
    "        # then empty string\n",
    "        .then(pl.lit(None))  \n",
    "\n",
    "        # Case 2: if about_the_game and not detailed_description\n",
    "        .when((pl.col(\"about_the_game\") != \"\") & (pl.col(\"detailed_description\") == \"\"))\n",
    "        # then about_the_game\n",
    "        .then(  \n",
    "            pl.concat_str([\n",
    "                pl.lit(\"[about_the_game]\\n\"),\n",
    "                pl.col(\"about_the_game\")\n",
    "            ], separator=\"\")\n",
    "        )\n",
    "        \n",
    "        # Case 3: if not about_the_game and detailed_description\n",
    "        .when((pl.col(\"about_the_game\") == \"\") & (pl.col(\"detailed_description\") != \"\"))\n",
    "        # then detailed_description\n",
    "        .then(\n",
    "            pl.concat_str([\n",
    "                pl.lit(\"[detailed_description]\\n\"),\n",
    "                pl.col(\"detailed_description\")\n",
    "            ], separator=\"\")\n",
    "        )\n",
    "\n",
    "        # Case 4: if both but different\n",
    "        .when(pl.col(\"desc_has_diff\"))\n",
    "        # then about_the_game + detailed_description\n",
    "        .then(  \n",
    "            pl.concat_str([\n",
    "                pl.lit(\"[about_the_game]\\n\"),\n",
    "                pl.col(\"about_the_game\"),\n",
    "                pl.lit(\"\\n\\n[detailed_description]\\n\"),\n",
    "                pl.col(\"detailed_description\")\n",
    "            ], separator=\"\")\n",
    "        )\n",
    "\n",
    "        # Case 5: if both but same\n",
    "        .otherwise(  # Case 5: both present but identical or not different enough\n",
    "            pl.concat_str([\n",
    "                pl.lit(\"[detailed_description]\\n\"),\n",
    "                pl.col(\"detailed_description\")\n",
    "            ], separator=\"\")\n",
    "        )\n",
    "        .alias(\"detailed_description\"),\n",
    "        \n",
    "        # Short description\n",
    "        pl.when(\n",
    "            pl.col('short_description') == ''\n",
    "        )\n",
    "        .then(\n",
    "            pl.lit(None)\n",
    "        )\n",
    "        .otherwise(\n",
    "            pl.col('short_description')\n",
    "        )\n",
    "        .alias('short_description')\n",
    "    )\n",
    "\n",
    "    # Add boolean flag for non-empty final description\n",
    "    .with_columns(\n",
    "        ~(\n",
    "            pl.concat_str([\n",
    "                pl.col(\"detailed_description\").fill_null(''),\n",
    "                pl.col(\"short_description\").fill_null(''),\n",
    "                pl.col(\"content_descriptors.notes\").fill_null('')\n",
    "            ])\n",
    "            .str.strip_chars()\n",
    "            .str.len_chars() > 0\n",
    "        )\n",
    "        .alias(\"enrich.is_description\")\n",
    "    )\n",
    "\n",
    "    # Drop temp columns\n",
    "    .drop(\"desc_has_diff\", \"about_the_game\")\n",
    ")\n",
    "\n",
    "df_merged_descriptions.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb12e5",
   "metadata": {},
   "source": [
    "### Cleaned dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_dates = (\n",
    "    df_merged_descriptions\n",
    "    .with_columns(\n",
    "        pl.coalesce([\n",
    "            pl.col(\"release_date.date\").str.to_titlecase().str.strptime(pl.Date, \"%d %b %Y\", strict=False), # 1 Jan 2025\n",
    "            pl.col(\"release_date.date\").str.to_titlecase().str.strptime(pl.Date, \"%d. %b. %Y\", strict=False), # 1. Jan. 2025\n",
    "            pl.col(\"release_date.date\").str.strptime(pl.Date, \"%d %b, %Y\", strict=False), # 1 Jan, 2025\n",
    "            pl.col(\"release_date.date\").str.strptime(pl.Date, \"%b %d, %Y\", strict=False), # Jan 1, 2025\n",
    "        ]).alias(\"release_date.date\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        ~(pl.col(\"release_date.date\").is_not_null())\n",
    "        .alias(\"enrich.is_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Check that dates are cleaned correctly\n",
    "(\n",
    "    df_cleaned_dates\n",
    "    .filter(\n",
    "        (pl.col(\"enrich.is_date\"))\n",
    "    )\n",
    "    .select([\n",
    "        \"appid\",\n",
    "        \"name\",\n",
    "        \"type\",\n",
    "        \"release_date.date\",\n",
    "        \"enrich.is_date\"\n",
    "    ])\n",
    "    .sort('release_date.date', descending=True)\n",
    ").head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c692f1a",
   "metadata": {},
   "source": [
    "### Cleaned computer specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894399a",
   "metadata": {},
   "source": [
    "Add a check to see if the computer specs are filled even when certain OS is true (that it is not only a template)\n",
    "\n",
    "this means a boolean column should be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e450ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_computer_specs = (\n",
    "    df_cleaned_dates\n",
    "    .with_columns(\n",
    "        # Windows Minimum\n",
    "        pl.when(\n",
    "            ~(pl.col('platforms.windows')) |\n",
    "            (pl.col('pc_requirements.minimum')\n",
    "            .str.strip_chars()\n",
    "            .str.strip_chars(\":\")  # remove trailing colons just in case\n",
    "            .str.to_lowercase() == \"minimum\")\n",
    "        )\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col('pc_requirements.minimum'))\n",
    "        .alias('pc_requirements.minimum'),\n",
    "\n",
    "        # Windows Recommended\n",
    "        pl.when(\n",
    "            ~(pl.col('platforms.windows')) |\n",
    "            (pl.col('pc_requirements.recommended')\n",
    "            .str.strip_chars()\n",
    "            .str.strip_chars(\":\")\n",
    "            .str.to_lowercase() == \"recommended\")\n",
    "        )\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col('pc_requirements.recommended'))\n",
    "        .alias('pc_requirements.recommended'),\n",
    "\n",
    "        # Mac Minimum\n",
    "        pl.when(\n",
    "            ~(pl.col('platforms.mac')) |\n",
    "            (pl.col('mac_requirements.minimum')\n",
    "            .str.strip_chars()\n",
    "            .str.strip_chars(\":\")\n",
    "            .str.to_lowercase() == \"minimum\")\n",
    "        )\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col('mac_requirements.minimum'))\n",
    "        .alias('mac_requirements.minimum'),\n",
    "\n",
    "        # Mac Recommended\n",
    "        pl.when(\n",
    "            ~(pl.col('platforms.mac')) |\n",
    "            (pl.col('mac_requirements.recommended')\n",
    "            .str.strip_chars()\n",
    "            .str.strip_chars(\":\")\n",
    "            .str.to_lowercase() == \"recommended\")\n",
    "        )\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col('mac_requirements.recommended'))\n",
    "        .alias('mac_requirements.recommended'),\n",
    "\n",
    "        # Linux Minimum\n",
    "        pl.when(\n",
    "            ~(pl.col('platforms.linux')) |\n",
    "            (pl.col('linux_requirements.minimum')\n",
    "            .str.strip_chars()\n",
    "            .str.strip_chars(\":\")\n",
    "            .str.to_lowercase() == \"minimum\")\n",
    "        )\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col('linux_requirements.minimum'))\n",
    "        .alias('linux_requirements.minimum'),\n",
    "\n",
    "        # Linux Recommended\n",
    "        pl.when(\n",
    "            ~(pl.col('platforms.linux')) |\n",
    "            (pl.col('linux_requirements.recommended')\n",
    "            .str.strip_chars()\n",
    "            .str.strip_chars(\":\")\n",
    "            .str.to_lowercase() == \"recommended\")\n",
    "        )\n",
    "        .then(pl.lit(None))\n",
    "        .otherwise(pl.col('linux_requirements.recommended'))\n",
    "        .alias('linux_requirements.recommended'),\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Enrich Windows\n",
    "        pl.when(\n",
    "            (pl.col('platforms.windows')) & \n",
    "            (\n",
    "                (pl.col('pc_requirements.minimum').is_null()) &\n",
    "                (pl.col('pc_requirements.recommended').is_null())\n",
    "            )\n",
    "        )\n",
    "        .then(pl.lit(True))\n",
    "        .otherwise(pl.lit(False))\n",
    "        .alias('enrich.is_windows'),\n",
    "\n",
    "        # Enrich Mac\n",
    "        pl.when(\n",
    "            (pl.col('platforms.mac')) & \n",
    "            (\n",
    "                (pl.col('mac_requirements.minimum').is_null()) &\n",
    "                (pl.col('mac_requirements.recommended').is_null())\n",
    "            )\n",
    "        )\n",
    "        .then(pl.lit(True))\n",
    "        .otherwise(pl.lit(False))\n",
    "        .alias('enrich.is_mac'),\n",
    "\n",
    "        # Enrich Linux\n",
    "        pl.when(\n",
    "            (pl.col('platforms.linux')) & \n",
    "            (\n",
    "                (pl.col('linux_requirements.minimum').is_null()) &\n",
    "                (pl.col('linux_requirements.recommended').is_null())\n",
    "            )\n",
    "        )\n",
    "        .then(pl.lit(True))\n",
    "        .otherwise(pl.lit(False))\n",
    "        .alias('enrich.is_linux')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_cleaned_computer_specs.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0209a1",
   "metadata": {},
   "source": [
    "### Cleaned price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_price = (\n",
    "    df_cleaned_computer_specs\n",
    "    .with_columns(\n",
    "        # Divide price by 100\n",
    "        (pl.col('price_overview.initial') / 100).alias('price_overview.initial'),\n",
    "        # Enrich Price\n",
    "        pl.when(\n",
    "            ~(pl.col('is_free')) & \n",
    "            (\n",
    "                (pl.col('price_overview.currency').is_null()) |\n",
    "                (pl.col('price_overview.initial').is_null())\n",
    "            )\n",
    "        )\n",
    "        .then(pl.lit(True))\n",
    "        .otherwise(pl.lit(False))\n",
    "        .alias('enrich.is_price')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_cleaned_price.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3df6e6",
   "metadata": {},
   "source": [
    "## Indexing / Sorting (merging purposes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176abe65",
   "metadata": {},
   "source": [
    "## Column reordering & renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = (\n",
    "    df_cleaned_price\n",
    "    # Reorder and Rename columns\n",
    "    .select(\n",
    "        # Keys\n",
    "        'appid', 'name', \n",
    "        pl.col('fullgame.appid').alias('game_appid'),\n",
    "        # Game descriptions\n",
    "        pl.col('enrich.is_description').alias('enrich_is_description'), \n",
    "        pl.col('detailed_description').alias('long_description'),\n",
    "        'short_description',\n",
    "        # Images / Movies\n",
    "        pl.col('header_image').alias('image_header'),\n",
    "        pl.col('background_raw').alias('image_background'),\n",
    "        pl.col('screenshots').alias('image_screenshots'),\n",
    "        pl.col('movies').alias('image_movies'),\n",
    "        # Price\n",
    "        pl.col('enrich.is_price').alias('enrich_is_price'),\n",
    "        'is_free', \n",
    "        pl.col('price_overview.currency').alias('currency'),\n",
    "        pl.col('price_overview.initial').alias('price'),\n",
    "        # Meta\n",
    "        'type', 'categories', 'genres', 'supported_languages', \n",
    "        pl.col('controller_support').alias('is_controller_support'),\n",
    "        # Date\n",
    "        pl.col('enrich.is_date').alias('enrich_is_date'),\n",
    "        pl.col('release_date.date').alias('release_date'),\n",
    "        # Age\n",
    "        'required_age',\n",
    "        # Contract\n",
    "        'developers', 'publishers', \n",
    "        pl.col('content_descriptors.notes').alias('content_descriptors_notes'),\n",
    "        # Progress\n",
    "        pl.col('achievements.highlighted').alias('achievements'),\n",
    "        # Computer Specs\n",
    "        pl.col('enrich.is_windows').alias('enrich_is_windows'),\n",
    "        pl.col('platforms.windows').alias('is_windows'), \n",
    "        pl.col('pc_requirements.minimum').alias('windows_requirements_minimum'),\n",
    "        pl.col('pc_requirements.recommended').alias('windows_requirements_recommended'),\n",
    "        pl.col('enrich.is_mac').alias('enrich_is_mac'),\n",
    "        pl.col('platforms.mac').alias('is_mac'),\n",
    "        pl.col('mac_requirements.minimum').alias('mac_requirements_minimum'),\n",
    "        pl.col('mac_requirements.recommended').alias('mac_requirements_recommended'),\n",
    "        pl.col('enrich.is_linux').alias('enrich_is_linux'),\n",
    "        pl.col('platforms.linux').alias('is_linux'),\n",
    "        pl.col('linux_requirements.minimum').alias('linux_requirements_minimum'),\n",
    "        pl.col('linux_requirements.recommended').alias('linux_requirements_recommended'),\n",
    "    )\n",
    ")\n",
    "df_final.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335feb3",
   "metadata": {},
   "source": [
    "## Test: Data Quality Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b5371",
   "metadata": {},
   "source": [
    "### Check Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac01ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check Column Structure\n",
    "\n",
    "\n",
    "\n",
    "# 2. Check Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26960447",
   "metadata": {},
   "source": [
    "### Check Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check Cleanup\n",
    "\n",
    "# 2. Check merged required_ages / range (0, 21)\n",
    "\n",
    "# 3. Check merged descriptions\n",
    "\n",
    "# 4. Check cleaned dates\n",
    "\n",
    "# 5. Check cleaned computer specs\n",
    "\n",
    "# 6. Check cleaned price\n",
    "\n",
    "# 7. Check renamed columns\n",
    "\n",
    "# 8. Check ordered columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa70b96",
   "metadata": {},
   "source": [
    "## Load to Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ac026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "def to_pg_array_str_safe(value):\n",
    "    \"\"\"\n",
    "    Converts a list of strings to a properly escaped PostgreSQL array literal.\n",
    "    Handles quotes, commas, and special characters.\n",
    "    \"\"\"\n",
    "    def escape_pg_string(s):\n",
    "        # Escape backslashes first\n",
    "        s = s.replace('\\\\', '\\\\\\\\')\n",
    "        # Escape double quotes by doubling them\n",
    "        s = s.replace('\"', '\\\\\"')  # use \\\\\" instead of double double-quotes\n",
    "        return f'\"{s}\"'\n",
    "\n",
    "    return \"{\" + \",\".join(escape_pg_string(v) for v in value) + \"}\"\n",
    "\n",
    "# Convert to Python-native list of dicts\n",
    "df_dicts = df_final.collect().to_dicts()\n",
    "\n",
    "for row in df_dicts:\n",
    "    for key, value in row.items():\n",
    "        if isinstance(value, list) and all(isinstance(v, str) for v in value):\n",
    "            row[key] = to_pg_array_str_safe(value)\n",
    "        elif isinstance(value, (list, dict)):\n",
    "            row[key] = json.dumps(value)\n",
    "\n",
    "# Convert back to Polars DataFrame\n",
    "df_final_cleaned = pl.DataFrame(df_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ef9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_manager = postgres_manager.PostgresManager()\n",
    "postgres_manager.load_app_details(df_final_cleaned) # with upsert logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca27f7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612507f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9266280a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ed031da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eebd2b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f97c8ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
