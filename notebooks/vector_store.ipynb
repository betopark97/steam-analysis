{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726c9f7c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os \n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Data Type\n",
    "import json\n",
    "from textwrap import dedent\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537c391",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "print(\"Project root added to path.\")\n",
    "\n",
    "env_path = Path.cwd().parent / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Load environment variables\n",
    "print(f\"Environment variables loaded: {load_dotenv()}.\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5e558",
   "metadata": {},
   "source": [
    "# Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e71198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "# show only the first 100 characters of the stringified vector\n",
    "print(str(query_result)[:100] + \"...\")\n",
    "\n",
    "\n",
    "# Alternative\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(\n",
    "#     model=\"models/gemini-embedding-exp-03-07\",\n",
    "#     google_api_key=os.environ.get(\"GEMINI_API_KEY\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3da5e",
   "metadata": {},
   "source": [
    "# PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "pg_user = os.environ.get('DB_USER')\n",
    "pg_password = os.environ.get('DB_PASSWORD')\n",
    "pg_db = os.environ.get('DB_NAME')\n",
    "pg_host = os.environ.get('DB_HOST')\n",
    "pg_port = os.environ.get('DB_PORT')\n",
    "schema = 'vector_store,public'\n",
    "connection = (\n",
    "    f\"postgresql+psycopg://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "    f\"?options=-csearch_path%3D{schema}\"\n",
    ")\n",
    "collection_name = \"game_embeddings\"\n",
    "distance_strategy = 'cosine'\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    "    distance_strategy=distance_strategy,\n",
    "    # pre_delete_collection=True      # Set to True to delete the collection before adding documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f06faa",
   "metadata": {},
   "source": [
    "# Read Document Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "db_params = {\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'database': os.getenv('DB_NAME'),\n",
    "    'port': os.getenv('DB_PORT')\n",
    "}\n",
    "\n",
    "with psycopg2.connect(**db_params) as conn:\n",
    "    cur = conn.cursor()\n",
    "    query = (\n",
    "        sql\n",
    "        .SQL(\n",
    "            \"\"\"\n",
    "            SELECT \n",
    "                * \n",
    "            FROM {table}\n",
    "            WHERE metadata ->> %s IS NOT NULL;\n",
    "            \"\"\"\n",
    "        )\n",
    "        .format(\n",
    "            table=sql.Identifier('vector_store', 'documents')\n",
    "        )\n",
    "    )\n",
    "    cur.execute(query, ('document_hash',))\n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    df = pl.DataFrame(rows, schema=columns, orient='row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from tqdm.notebook import tqdm\n",
    "from more_itertools import chunked\n",
    "\n",
    "\n",
    "# Step 1: Convert your DataFrame rows to Documents\n",
    "raw_docs = []\n",
    "\n",
    "for row in df.rows(named=True):\n",
    "    text = row[\"document\"]\n",
    "    metadata = row[\"metadata\"]\n",
    "    raw_docs.append(Document(page_content=text, metadata=metadata))\n",
    "    \n",
    "# Chunking raw_docs\n",
    "chunks = list(chunked(raw_docs, 1000))\n",
    "for chunk in tqdm(chunks, desc=\"Batch Processing Documents to Vector Store\"):\n",
    "    \n",
    "    # Step 2: Use a text splitter to chunk the content\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,       # Adjust based on your embedding model's context length\n",
    "        chunk_overlap=50,     # Helps maintain context across chunks\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    # Step 3: Split the raw documents into smaller chunks\n",
    "    split_docs = text_splitter.split_documents(chunk)\n",
    "\n",
    "    # Step 4: Add to vector store\n",
    "    vector_store.add_documents(split_docs, ids=[f\"{doc.metadata[\"appid\"]}-{doc.metadata[\"start_index\"]}\" for index, doc in enumerate(split_docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Recommend me a game that has cowboys in it\"\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query,\n",
    "    k=5\n",
    ")\n",
    "for doc, score in results:\n",
    "    game_name = doc.metadata['name']\n",
    "    game_score = score\n",
    "    print(f\"* [SIM={score:3f}] {game_name}\")\n",
    "    print(doc.page_content[:300], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a326589",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
    "retriever.invoke(\"kitty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3aeba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
